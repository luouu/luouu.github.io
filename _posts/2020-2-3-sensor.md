---
layout: post
title: Sensor
categories: [sensor]
description: 
keywords: 
topmost: false
---

* TOC
{:toc}

## 介绍

Sensor 将从 lens 上传导过来的光线转换为电信号，再经过内部AD转换为数字信号。每个pixel像素点只能感受R、G、B中的一种，因此每个像素点中存放的数据是单色光，像素表示的就是有多少个感光点，每个感光点只能感应一种光，这些最原始的感光数据我们称为RAW Data。Raw Data数据要经过ISP的处理才能还原出三原色，也就是说如果一个像素点感应为R值，那么ISP会根据该感光点周围的G、B的值，通过插值和特效处理等，计算出该R点的G、B值，这样该点的RGB就被还原了。目前常用的sensor有两种，一种是CCD（电荷耦合）；一种是CMOS（金属氧化物导体）。

* CCD（Charge Coupled Device），电荷耦合器件传感器：使用一种高感光度的半导体材料制成，能把光线转变成电荷，通过模数转换器芯片转换成电信号。CCD由许多独立的感光单位组成，通常以百万像素为单位。当CCD表面受到光照时，每个感光单位都会将电荷反映在组件上，所有的感光单位产生的信号加在一起，就构成了一幅完整的图像。CCD传感器以日本厂商为主导，全球市场上有90%被日本厂商垄断，索尼、松下、夏普是龙头。
* CMOS（Complementary Metal-Oxide Semiconductor），互补性氧化金属半导体：主要是利用硅和锗做成的半导体，使其在CMOS上共存着带N(-)和P(+)级的半导体，这两个互补效应所产生的电流可以被处理芯片记录并解读成影像。CMOS传感器主要以美国、韩国和中国台湾为主导，主要生产厂家是美国的OmnVison、Agilent、Micron，中国台湾的锐像、原相、泰视等，韩国的三星、现代。

## ISP

ISP 是图像信号处理器（Image Sensor Processor）。一般用来处理Image Sensor（图像传感器）的输出数据，如做AE（自动曝光）、AGC（自动增益控制）、AWB（自动白平衡）、色彩校正、Lens Shading、Gamma 校正、祛除坏点、Auto Black Level、Auto White Level 等等功能的处理。

### AE

自动曝光（Auto Exposure），根据外界光线的强弱自动调整曝光量和增益，防止曝光过度或者不足。AE 算法的主要调控对象一般是光圈、sensor增益（包含模拟增益和数字增益）、ISP数字增益这三个参数。

影响曝光的因素有曝光时间；光圈大小；Sensor的ISO感光度。

帧曝光时间Ft和帧率f的关系为：f = 1 / Ft，曝光时间的计算方法由sensor厂商提供。

EV曝光值（exposure value），摄影技术中定义的曝光值参数，代表能够给出同样曝光的所有相机光圈组合。它的定义是：$EV = \log(N^2 \div t)$
其中N是光圈的f-stop值；t是曝光时间，单位为秒。

EV0 对应于ISO100，曝光时间为1秒，光圈为f/1.0，以及与之等效的所有曝光组合，这些组合可以使18%的中性灰卡在所处光照条件下获得合适的曝光。因此曝光值主要体现了拍摄场景的亮度，同时在一定程度上也能反映相机的灵敏度。

曝光值每增加1称为增加一挡曝光，也就是将曝光量减半，比如将曝光时间或光圈面积减半，因此可以从EV0出发，按照光圈、快门加倍或减半的方式推导出其余的曝光档位，一般常用的档位在-6~20之间。

如果已知使画面正确曝光的EV值，则可以在下表中选择一个合适的曝光时间+光圈组合。举例来说，假设已知某拍摄场景正确曝光需要EV2，在固定ISO100的前提下，光圈和快门组合只能在（1s,f/2），（1/2s,f/1.4），（1/4s,f/1）这三个方案中选择一个。

![img](/images/sensor/v2-c02e83e125e4c8ef22e1ed881274f0a0_b.jpg)

下表给出了EV0~EV20的典型场景。
![img](/images/sensor/v2-6e533fff18f0d918e10799c77da24350_b.jpg)

下表给出了更完整的EV数据，同时包含了ISO，光圈和快门值
![img](/images/sensor/v2-fdcf59270dee877d6e1b9d79bf9c625f_b.jpg)

光圈、快门、增益都可以影响画面亮度，但是这三者在效能上并不是完全等价的。摄影领域常用一个曝光三角形来形象地阐释三者之间的关系。
![img](/images/sensor/v2-af09e43949d8c5d8dc36214597209286_b.jpg)

光圈（aperture）的副作用主要是影响景深。快门的副作用主要是影响运动模糊。一般而言，当曝光时间大于15ms时，画面中速度大于40km/h的车辆就会开始变模糊。当曝光时间大于30ms时，画面中走动的人就会变模糊。因此拍摄对象的预期移动速度基本上决定了曝光时间的上限。增益的副作用主要表现为画面噪声，尤其是数字增益会引入较大的噪声，显著降低图像质量。
![img](/images/sensor/v2-ed7c2425f86f43612ef449e0bff2ce4a_b.jpg)

### AWB

色温随可见光的光谱成分变化而变化，在低色温光源下，白色物体偏红，在高色温光源下，白色物体偏蓝。人眼可根据大脑的记忆判断，识别物体的真实颜色，AWB（自动白平衡调整Auto White Balance ） 算法的功能是降低外界光源对物体真实颜色的影响，使得我们采集的颜色信息转变为在理想日光光源下的无偏色信息。要求在不同色温环境下，照白色的物体，屏幕中的图像应也是白色的。

* 色温的定义：将黑体从绝对零度开始加温，当温度升高到一定程度时候，黑体便辐射出可见光，其光谱成份以及给人的感觉也会着温度的不断升高发生相应的变化。于是，就把黑体辐射一定色光的温度定为发射相同色光光源的色温。

* 白平衡：在不同色温的光源下，白色在传感器中的响应会偏蓝或偏红。白平衡算法通过调整 R, G, B 三个颜色通道的强度，使白色真实呈现。

### 3DNR

2D降噪：只在2维空间域上进行降噪处理。对一个像素将其与周围像素平均，平均后噪声降低，但缺点是会造成画面模糊，特别是物体边缘部分。因此对这种算法的改进主要是进行边缘检测，边缘部分的像素不用来进行模糊。

3D降噪即3D DNR（3D Digital Noise Reducer），通过对比相邻的几帧图像，将图像信号中不重叠的噪波自动滤出。目前比较普遍的是进行Y/C分离，即从视频信号中将亮度信号（Y）和颜色信号（C）分离，然后对Y信号，C信号进行3维数字降噪。3D降噪增添了时域处理，因此变为3维。和2D降噪的不同在于，2D降噪只考虑一帧图像，而3D降噪进一步考虑帧与帧之间的时域关系，对每个像素进行时域上的平均，故计算量大，耗时更长。

### BLC

BLC（Black Level Correction）/ Black Level Compensate (OBC) ：黑电平校正。黑电平是在没有外界光线输入时，理想情况下像素值应该是0，但是实际中因为sensor暗电流作用仍会输出的亮度值。ISP 需要减去这个亮度值（这一个值会受到AWBGain，CCM，Gamma的影响）。

### LSC

LSC（Lens Shading Correction）/Color Shading ：阴影校正。Lens Shading是由于镜片从边缘到中心对入射光线的反射程度不同，镜头中心接收的光强大，边缘接收的光强较少， 造成图像从中心到边缘亮度逐渐变暗。Color Shading是由于Lens从中心到边缘，其R、G、B变暗的速率不一样，总体表现就是Gb/Gr像素值差异较大，两个像素之间有细微纹理。

### CCM

CCM（Color Correction Matrix/ DSC color calibration）：颜色校正矩阵。sensor 对光谱的响应在 RGB 各分量上与人眼对光谱的响应通常是有偏差的，拍摄color checker24色板，将相机拍摄图片值与色板标准值之间进行对比，得出一组能将拍摄值校正到最接近标准值的3x3矩阵。通常通过一个色彩校正矩阵对所有相机拍摄的图片进行颜色校正，使图像与人眼视觉在色彩上保持一致。

![image-20200221200943546](/images/sensor/image-20200221200943546.png)
m~RR~ + m~RG~ + m~RB~ = 256
m~GR~ + m~GG~ + m~GB~ = 256
m~BR~ + m~BG~ + m~BB~ = 256

（2）DPC/BPD（Defect Pixel Correction/Bad Pixel Detect）：坏点校正/坏点检测。相机中成像坏点一般是白色或者黑色的点，和周围像素点的差异明显。

（3）FPN（Fix Pattern Noise）：固定模式噪声。由于CMOS每个感光二极体旁都搭配一个ADC 放大器，如果以百万像素计，那么就需要百万个以上的 ADC 放大器，但是每个像素结构中的光电二极管的尺寸、掺杂浓度、生产过程中的沾污以及MOS场效应管的参数的偏差等都会造成像素输出信号的变化。对于给定的单个像素它是固定的。通常消除固定模式噪声采用“双采样降噪”方法，这是CMOS 感光器件特有的一种降噪方式。在光线较暗的环境下使用时，画面会有明显的噪声，这时通过对景物进行两次不同曝光率和敏感度的采样，然后将两次采样的结果进行综合处理，就可以有效解决低照度下的图像噪声问题。

（5）Flare offset：光学上称Flare也叫stray light,耀斑补偿。镜片的表面反射或镜筒、反光镜组的内面所引起的反射光，到达底面后造成画面整体或一部份产生了雾蒙，降低了图像的鲜锐度。镜片的镀膜及内面防反射处理的加强，固然可以大幅度地减少光斑，但被摄体的状况并不相同，不可能完全消除。

因此，在相机里面设计都是黑色的，且其内侧表明设计都是粗糙的，目前就是为了减小flare。flare如何修正？做直方图，然后每阶的亮度都往下降，这样是否会影响颜色呢？因此，flare一定要是在linear domain去做，不能在RGB domain去做。

（9）DM（Demosaicing/Color Filter Array Interpolation/CFA插值）：CMOS Sensor出来的RawData是Bayer格式的图像，每个像素只有一个通道的信息。DM是将Bayer格式的图像恢复成每个像素用RGB三通道表示的方式。DM的主要依据是图像在平滑的局部区域，各分量的ratio是相等的。插值算法的好坏会影响图片的细节，如摩尔纹。

（12）EE（Edge Enhancement/Edge Sharpening）：锐化，边缘增强。通过滤波器获取图像的高频分量，按照一定的比例将高频部分和原图进行加权求和获取锐化后的图像。

（13）DRC/HDR（Dynamic Range Compression/ High-Dynamic Range）：宽动态。高动态图像的拍摄出来的结果通常会有，亮部太亮，暗部太暗的问题。DRC是调整图像暗部亮度使之变亮，调整亮部亮度使之变暗，而且保持图像的对比度。

（14）PCA/VDE：Hue，Saturation，Contrast，Brightness调试。单独针对Hue，Saturation，Contrast，Brightness各图像分量进行调节。

（15）Histogram：直方图均衡化。重新分布图片的亮度。使图片的亮度分布更加均匀。

（16）FlashLight Control：闪光灯控制

（17）Cross talk：Optical cross-talk是当主光线进光角度过大，导致光线不能有效地进入本像素的Microlens内，而是进入相邻像素单元或其他无效区域内的现象。

Electric cross-talk：相邻单元之间的光生少数载流子通过衬底扩散和漏电相互影响造成相邻单元的现象。

上述原因导致结果都是图像在对角线上相邻两个像素的Gr和Gb value差异较大而产生不平滑的纹理状。

（18）Gradation Control（GDC）：可能是对图像数据精度进行的操作

（19）Scaler：对图像进行缩放，缩放的过程中采样和插值直接影响图像的细节质量。

（20）Adaptive tone scale：(这个没有办法处理多种场景)进来的影像，根据histogram，可以调节，让其明暗亮度的曲线比较好看。因此，它最重要的就是histogram equalization，其关键是在哪个domain去做。目前我们的做法应该是在L*做histogram，但只做edge的histogram，这样就ok了。

（21）Dynamic Range Compression：就是把暗的地方变亮一些，亮的地方变暗一些。AE的主要目的是避免亮度饱和的pixels，其余exposure的pixel可以通过DRC校准回来。

## Iris

光圈是镜头上的一个组件，由机械或电压控制，可通过控制通光孔的开合程度，控制进光量的大小，光圈的进光量与其f值的平方成反比。DC-Iris不能精确定位，P-Iris能精确定位。

计量光学系统的通光量时使用f-stop作为计量单位，f-stop = f （镜头焦距）/ D（光圈孔径），f-stop值越大表示光圈孔径越小，常用的f-stop值一般在1.4~22之间,如下图所示。
![img](/images/sensor/v2-910b34243ef1be1dfba55f6f564290a0_720w.jpg)

由于f-stop反比于光圈孔径，根据圆面积公式S=πD^2/4，镜头的实际通光量与f-stop的平方成反比，它们之间名义上的对应关系如下。
![img](/images/sensor/v2-907684804fe2f746a039be86ab42a9cf_720w.jpg)

一般来说，光圈f值从f1.8~f22较常见， 其中 f1.8~f5.4，室内用得多一些；而f5.0以上室外用得多，暗场景一般使用最小的f值光圈以获得较大的通光量。
